{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import json, requests\n",
    "import Levenshtein as lev\n",
    "import unicodedata\n",
    "import pandas as pd\n",
    "import urllib\n",
    "import os, os.path\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "ID = \"aaf20ac1\"\n",
    "key = \"7bd88c15c64569da8de3c414ace8d236\"\n",
    "\n",
    "baseURL = \"http://api.yummly.com/v1/api/recipes?_app_id=\"+ID+\"&_app_key=\"+key+\"&q=@&maxResult=51\"\n",
    "baseURLGet = \"http://api.yummly.com/v1/api/recipe/@?_app_id=\"+ID+\"&_app_key=\"+key\n",
    "\n",
    "noImages = []\n",
    "csvList = []\n",
    "jsonBackup = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def convertName(name):\n",
    "    converted = unicodedata.normalize('NFKD', name).encode('ascii','ignore')\n",
    "    return converted.lower()\n",
    "\n",
    "def bestMatch(query, response):\n",
    "    tmpQuery = query.lower()\n",
    "    levDistances = [lev.distance(convertName(match[\"recipeName\"]), tmpQuery) for match in response[\"matches\"]]\n",
    "    return response[\"matches\"][levDistances.index(min(levDistances))]\n",
    "\n",
    "def getRecipe(candidateID):\n",
    "    url = baseURLGet.replace(\"@\", candidateID)\n",
    "    response = json.loads(requests.get(url).text)\n",
    "    return response\n",
    "\n",
    "def buildJson(original, searchResponse, recipeResponse):\n",
    "    jsonBuilder = {}\n",
    "\n",
    "    jsonBuilder[\"RecipeURL\"] = recipeResponse[\"source\"][\"sourceRecipeUrl\"]\n",
    "    jsonBuilder[\"CleanIngredients\"] = searchResponse[\"ingredients\"]\n",
    "    jsonBuilder[\"RawIngredients\"] = recipeResponse[\"ingredientLines\"]\n",
    "    jsonBuilder[\"RecipeName\"] = searchResponse[\"recipeName\"]\n",
    "    jsonBuilder[\"FoodName\"] = original\n",
    "    return jsonBuilder\n",
    "\n",
    "def rangeMatch(query, response):\n",
    "    tmpQuery = query.lower()\n",
    "    levDistances = [lev.distance(convertName(match[\"recipeName\"]), tmpQuery) for match in response[\"matches\"]]\n",
    "    response[\"matches\"].pop(levDistances.index(min(levDistances)))\n",
    "    return response[\"matches\"]\n",
    "\n",
    "def saveImageFromUrl(query, recipeName, index, lstURL):\n",
    "    tmpQuery = (query.replace(\" \", \"_\")).lower()\n",
    "    tmpRecipeName = (recipeName.replace(\" \", \"_\")).lower()\n",
    "    tmpRecipeName = unicodedata.normalize('NFKD', tmpRecipeName).encode('ascii','ignore')\n",
    "    \n",
    "    candidate = \"hostedLargeUrl\"\n",
    "    try:\n",
    "        directory = \"food101Pictures/\"+tmpQuery\n",
    "        if not os.path.exists(directory):\n",
    "            os.makedirs(directory)\n",
    "\n",
    "        fileName = directory+\"/\"+str(index)+\"_\"+tmpRecipeName+\"_\"+candidate+\".jpg\"\n",
    "        urllib.urlretrieve(lstURL[0][candidate], fileName)\n",
    "        csvList.append((fileName, recipeName))\n",
    "        return fileName\n",
    "    except:\n",
    "        print \"Something went wrong and could not retrieve the image for \"+query+\" recipeName: \"+recipeName+\" and index \"+str(index)\n",
    "        return None\n",
    "\n",
    "def checkIfImage(response):\n",
    "    try:\n",
    "        response[0][\"hostedLargeUrl\"]\n",
    "        return True\n",
    "    except:\n",
    "        return False\n",
    "    \n",
    "def buildWideJson(original, searchResponse, recipeResponse, index):\n",
    "    jsonBuilder = {}\n",
    "    if recipeResponse[\"images\"] and checkIfImage(recipeResponse[\"images\"]):\n",
    "        fileName = saveImageFromUrl(original, searchResponse[\"recipeName\"], index, recipeResponse[\"images\"])\n",
    "        if fileName:\n",
    "            jsonBuilder[\"Images\"] = recipeResponse[\"images\"]\n",
    "            jsonBuilder[\"RecipeName\"] = searchResponse[\"recipeName\"]\n",
    "            jsonBuilder[\"RecipeURL\"] = recipeResponse[\"source\"][\"sourceRecipeUrl\"]\n",
    "            jsonBuilder[\"CleanIngredients\"] = searchResponse[\"ingredients\"]\n",
    "            jsonBuilder[\"RawIngredients\"] = recipeResponse[\"ingredientLines\"]\n",
    "            jsonBuilder[\"ImagePath\"] = fileName\n",
    "        else:\n",
    "            return None\n",
    "    else:\n",
    "        noImages.append(original+\" \"+searchResponse[\"recipeName\"])\n",
    "        return None\n",
    "    return jsonBuilder           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def searchFromList():\n",
    "    responses = []\n",
    "    notFound = []\n",
    "    foodList = pd.read_csv(\"food101.csv\", sep=',')\n",
    "    for query in foodList['FoodName']:\n",
    "        print \"query: \", query\n",
    "        params = query.lower().replace(\" \", \"+\")\n",
    "        url = baseURL.replace(\"@\",params)\n",
    "        response = json.loads(requests.get(url).text)\n",
    "        if not response[\"matches\"]:\n",
    "            \"Hello no matches :3\"\n",
    "            notFound.append(query)\n",
    "    \n",
    "        else:\n",
    "            candidate = bestMatch(query, response)\n",
    "            candidateID = candidate[\"id\"]\n",
    "            recipeResponse = getRecipe(candidateID)\n",
    "            builtJson = buildJson(query, candidate, recipeResponse)\n",
    "            responses.append(builtJson)\n",
    "            \n",
    "    data = json.dumps(responses)\n",
    "    with open('recipesData.json', 'w') as f:\n",
    "        json.dump(responses, f)\n",
    "    with open('notFound.json', 'w') as f:\n",
    "        json.dump(notFound, f)\n",
    "    \n",
    "    return responses, notFound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def searchRecipesRange():\n",
    "    notFound = []\n",
    "    foodList = pd.read_csv(\"food101.csv\", sep=',')\n",
    "    jsonBuilder = {}\n",
    "    for query in foodList['FoodName']:\n",
    "        print \"query: \", query\n",
    "        params = query.lower().replace(\" \", \"+\")\n",
    "        url = baseURL.replace(\"@\",params)\n",
    "        succeed = False\n",
    "        #Sometimes, calling the api in such a sort time causes it to shut down\n",
    "        #Let's not get out of here until we can get the api call\n",
    "        while not succeed:\n",
    "            try:\n",
    "                response = json.loads(requests.get(url).text)\n",
    "                succeed = True\n",
    "            except:\n",
    "                print \"Trying to reconnect...\"\n",
    "                jsonBackup = jsonBuilder\n",
    "                time.sleep(2)\n",
    "            \n",
    "        if not response[\"matches\"]:\n",
    "            \"Hello no matches :3\"\n",
    "            notFound.append(query)\n",
    "    \n",
    "        else:\n",
    "            matches = rangeMatch(query, response)\n",
    "            lst = []\n",
    "            i = 0\n",
    "            for match in matches:\n",
    "                candidateID = match[\"id\"]\n",
    "                recipeResponse = getRecipe(candidateID)\n",
    "                builtJson = buildWideJson(query, match, recipeResponse, i)\n",
    "                if builtJson:\n",
    "                    lst.append(builtJson)\n",
    "                    i+=1\n",
    "                \n",
    "            print \"For the class \"+query+\" it should be \"+str(i)+\" images from the \"+str(len(matches))+\" initially found\"\n",
    "            jsonBuilder[query] = lst\n",
    "            \n",
    "    jsonBackup = jsonBuilder\n",
    "    with open('recipesWideData.json', 'w') as f:\n",
    "        json.dump(jsonBuilder, f)\n",
    "    with open('notFoundWide.json', 'w') as f:\n",
    "        json.dump(notFound, f)\n",
    "        \n",
    "    df = pd.DataFrame.from_records(csvList, columns=[\"path_to_image\", \"recipeName\"])\n",
    "    df.to_csv(\"paths.csv\", index=False, encoding='utf-8')\n",
    "    data = json.dumps(jsonBuilder)\n",
    "    \n",
    "    return jsonBuilder, notFound\n",
    "\n",
    "#searchRecipesRange()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def checkCorrespondence():\n",
    "    with open('recipesWideData.json') as data_file:    \n",
    "        data = json.load(data_file)\n",
    "    foodList = pd.read_csv(\"food101.csv\", sep=',')\n",
    "    for query in foodList['FoodName']:\n",
    "        lengthJson = len(data[query])\n",
    "        folderName = (query.replace(\" \", \"_\")).lower()\n",
    "        DIR=\"food101Pictures/\"+folderName\n",
    "        lengthImages = len([name for name in os.listdir(DIR) if os.path.isfile(os.path.join(DIR, name))])\n",
    "        status = (lengthJson == lengthImages)\n",
    "        print\"For the query \"+query+\" the json has \"+str(lengthJson)+\" recipes and the folder has \"+str(lengthImages)+\" images, status is: \"+str(status)\n",
    "\n",
    "\n",
    "def checkForErrors():\n",
    "    with open('recipesWideDataCorrected.json') as data_file:    \n",
    "        data = json.load(data_file)\n",
    "    foodList = pd.read_csv(\"food101.csv\", sep=',')\n",
    "    for query in foodList['FoodName']:\n",
    "        lengthJson = len(data[query])\n",
    "        folderName = (query.replace(\" \", \"_\")).lower()\n",
    "        DIR=\"food101Pictures/\"+folderName\n",
    "        lst = [name for name in os.listdir(DIR) if os.path.isfile(os.path.join(DIR, name))]\n",
    "        lst.sort(key=lambda x: os.path.getmtime(DIR+\"/\"+x))\n",
    "        lengthImages = len(lst)\n",
    "        status = (lengthJson == lengthImages)\n",
    "        i = 0\n",
    "        for elem in data[query]:\n",
    "            fileName =  DIR+\"/\"+lst[i] \n",
    "            status = status and (elem[\"ImagePath\"] == fileName)\n",
    "            i+=1\n",
    "            \n",
    "        \n",
    "        print\"For query \"+query+\" the json has \"+str(lengthJson)+\" recipes and the folder has \"+str(lengthImages)+\" images, status is: \"+str(status)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def cleanData():\n",
    "    with open('recipesWideData.json') as data_file:    \n",
    "        data = json.load(data_file)\n",
    "\n",
    "    data[\"Apple pie\"].pop(40)\n",
    "    data[\"Baby back ribs\"].pop(42)\n",
    "    data[\"Baby back ribs\"].pop(39)\n",
    "    data[\"Beef Tacos\"].pop(5)\n",
    "    data[\"Beef tartare\"].pop(39)\n",
    "    data[\"Beef tartare\"].pop(17)\n",
    "    data[\"Beef tartare\"].pop(14)\n",
    "    data[\"Beef tartare\"].pop(1)\n",
    "    data[\"Beignets\"].pop(16)\n",
    "    data[\"Bread pudding\"].pop(21)\n",
    "    data[\"Breakfast burrito\"].pop(41)\n",
    "    data[\"Cannoli\"].pop(33)\n",
    "    data[\"Chicken wings\"].pop(36)\n",
    "    data[\"Chicken wings\"].pop(0)\n",
    "    data[\"Churros\"].pop(20)\n",
    "    data[\"Deviled eggs\"].pop(14)\n",
    "    data[\"Donuts\"].pop(30)\n",
    "    data[\"Dumplings\"].pop(6)\n",
    "    data[\"Eggs benedict\"].pop(16)\n",
    "    data[\"Escargots\"].pop(26)\n",
    "    data[\"Filet mignon\"].pop(33)\n",
    "    data[\"French fries\"].pop(35)\n",
    "    data[\"Fried calamari\"].pop(10)\n",
    "    data[\"Fried rice\"].pop(36)\n",
    "    data[\"Grilled salmon\"].pop(45)\n",
    "    data[\"Grilled salmon\"].pop(5)\n",
    "    data[\"Lobster bisque\"].pop(26)\n",
    "    data[\"Mussels\"].pop(30)\n",
    "    data[\"Omelette\"].pop(20)\n",
    "    data[\"Omelette\"].pop(13)\n",
    "    data[\"Onion rings\"].pop(19)\n",
    "    data[\"Pad thai\"].pop(9)\n",
    "    data[\"Oysters\"].pop(45)\n",
    "    data[\"Paella\"].pop(44)\n",
    "    data[\"Panna cotta\"].pop(41)\n",
    "    data[\"Peking duck\"].pop(14)\n",
    "    data[\"Prime rib\"].pop(15)\n",
    "    data[\"Ramen\"].pop(37)\n",
    "    data[\"Ramen\"].pop(10)\n",
    "    data[\"Sashimi\"].pop(19)\n",
    "    data[\"Seaweed salad\"].pop(48)\n",
    "    data[\"Spaghetti bolognese\"].pop(49)\n",
    "    data[\"Tiramisu\"].pop(16)\n",
    "    data[\"Tuna tartare\"].pop(38)\n",
    "    data[\"Tuna tartare\"].pop(33)\n",
    "    data[\"Tuna tartare\"].pop(28)\n",
    "    data[\"Tuna tartare\"].pop(14)\n",
    "\n",
    "    with open('recipesWideDataCorrected.json', 'w') as f:\n",
    "        json.dump(data, f)\n",
    "            \n",
    "cleanData()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
